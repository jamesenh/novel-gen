# 数据库与向量库渐进式落地方案

## 总体架构思路

### 设计原则
- **链保持无状态**：每个链仍然通过 JSON 文件传递信息
- **模型集中管理**：所有数据模型定义在 `models.py` 中
- **LangChain 只做调度**：不直接操作数据库，通过 tools 层访问
- **记忆分层存储**：
  - 结构化状态（强一致）→ 关系型/键值数据库
  - 非结构化记忆（弱一致）→ 向量数据库

### 两个层次的记忆系统
1. **结构化状态层**
   - 人物当前属性、位置、关系、物品持有、世界线旗标
   - 适合关系型数据库存储
   - 提供强一致性保证

2. **非结构化记忆层**
   - 之前章节/场景文字片段、人物对白、世界观说明、设定补充
   - 适合向量检索
   - 提供语义相似性查找

## 数据库层设计

### 选型建议
- **优先选择**：SQLite + SQLAlchemy/SQLModel
- **优势**：CLI 工具友好、本地生成适合、易于迁移
- **抽象层**：通过 `runtime/db.py` 提供统一接口，便于未来切换到 PostgreSQL

### 核心数据模型（Pydantic）

#### StoryProjectState
```python
class StoryProjectState(BaseModel):
    project_id: str
    settings: Settings
    world: WorldSetting
```

#### EntityKind（枚举）
```python
class EntityKind(str, Enum):
    CHARACTER = "character"
    ITEM = "item"
    LOCATION = "location"
    FACTION = "faction"
    MISC = "misc"
```

#### StoryEntity
```python
class StoryEntity(BaseModel):
    id: str
    project_id: str
    kind: EntityKind
    base_profile: Union[Character, dict]  # 基础档案
```

#### EntityStateSnapshot（关键）
```python
class EntityStateSnapshot(BaseModel):
    project_id: str
    entity_id: str
    chapter_index: int
    scene_index: int
    in_story_time: Optional[str]
    state: dict  # HP、位置、关系变化、flag 等
```

#### TimelineEvent
```python
class TimelineEvent(BaseModel):
    id: str
    project_id: str
    chapter_index: int
    scene_index: int
    in_story_time: Optional[str]
    summary: str
    tags: List[str]
```

### 数据库抽象层接口（runtime/db.py）

#### 写入接口
- `save_entity_base_profile(project_id, entity: StoryEntity)`
- `save_entity_state_snapshot(snapshot: EntityStateSnapshot)`
- `save_timeline_event(event: TimelineEvent)`

#### 查询接口
- `get_latest_entity_state(project_id, entity_id) -> EntityStateSnapshot | None`
- `get_entity_timeline(project_id, entity_id, limit: int) -> List[TimelineEvent]`
- `get_timeline_around(project_id, chapter_index, scene_index, window: int) -> List[TimelineEvent]`

## 向量数据库层设计

### 选型建议
- **本地优先**：Chroma 或 SQLite + pgvector/FAISS
- **抽象层**：通过 `runtime/vector_store.py` 提供统一接口

### 核心数据模型

#### StoryMemoryChunk
```python
class StoryMemoryChunk(BaseModel):
    id: str
    project_id: str
    chapter_index: int
    scene_index: int
    text: str
    entities: List[str]  # 涉及人物/物品 id
    tags: List[str]      # 如 ["relationship", "promise"]
    kind: Literal["scene", "summary", "note"]
```

#### StoryMemoryHit
```python
class StoryMemoryHit(BaseModel):
    chunk: StoryMemoryChunk
    score: float
```

### 向量库抽象层接口（runtime/vector_store.py）
- `add_memory_chunk(chunk: StoryMemoryChunk)`
- `search_memory(project_id, query, filters, top_k) -> List[StoryMemoryHit]`

## Function Call / Tools 设计

### 设计原则
- 工具实现在 `runtime/memory_tools.py`
- 只调用 `runtime/db.py` 和 `runtime/vector_store.py`
- LangChain 通过 tools 调用，保持 Pydantic 参数与返回值

### 核心工具接口

#### 1. get_entity_state
- **入参**：`project_id`, `entity_id`, `chapter_index`, `scene_index`
- **出参**：`EntityStateSnapshot` 或 `{"found": false}`
- **功能**：给 LLM 提供当前人物/物品状态的权威视图

#### 2. get_timeline
- **入参**：`project_id`, `from_chapter`, `to_chapter`, `entity_id (optional)`
- **出参**：`List[TimelineEvent]`
- **功能**：让模型看到最近发生了什么，避免剧情跳跃

#### 3. search_story_memory
- **入参**：`project_id`, `query`, `entities`, `top_k`
- **出参**：`List[StoryMemoryHit]`
- **功能**：在写场景前，找出所有和"这场戏"强相关的历史片段

## 与现有 Chains 的集成方式

### 新增记忆检索链
- **文件**：`chains/memory_context_chain.py`
- **输入**：`{Settings, ChapterPlan, ScenePlan, project_id}`
- **处理流程**：
  1. PromptTemplate 引导模型思考需要哪些人物/物品/线索
  2. LLM + tools 调用上述三个工具
  3. OutputParser 解析为 `SceneMemoryContext`
  4. 写入 JSON：`projects/<id>/scene_<x>_memory.json`

#### SceneMemoryContext 结构
```python
class SceneMemoryContext(BaseModel):
    relevant_entities: List[str]
    entity_states: Dict[str, EntityStateSnapshot]
    recent_events: List[TimelineEvent]
    relevant_memories: List[StoryMemoryHit]
```

### 现有 scene_text_chain 的改造（最小侵入）
- **输入增加**：`SceneMemoryContext`（从 JSON 读入）
- **Prompt 改造**：
  - 必须遵守 `entity_states` 中的状态
  - 使用 `recent_events` 和 `relevant_memories` 保持连续性
- **优势**：写文本的链仍然不需要 tools，只是多了一份结构化上下文

## 渐进式落地建议

### 阶段 1：只做持久化，不影响生成逻辑
**目标**：建立数据存储基础，不改变现有流程

**实施步骤**：
1. 增加 `models.py` 中的状态/记忆模型
2. 实现 `runtime/db.py` 基本写入功能：
   - 在 orchestrator 每步执行后，把链输出同步存一份 DB 快照
3. 实现 `runtime/vector_store.py`：
   - 把 `GeneratedScene` 文本分 chunk 写入向量库
4. **验证**：确保数据能正确存储，不影响现有生成流程

### 阶段 2：只读，不启用 function call
**目标**：验证数据设计和查询接口的正确性

**实施步骤**：
1. 写 CLI/辅助脚本：
   - 给定 `project_id + 场景`，打印人物当前状态和关键记忆
2. 手动调试一两部小说：
   - 验证状态/记忆设计是否合理
   - 检查查询结果的准确性
3. **验证**：确认数据模型设计符合实际需求

### 阶段 3：引入 memory_context_chain（LLM + tools）
**目标**：让 AI 能够智能检索相关记忆

**实施步骤**：
1. 实现 `chains/memory_context_chain.py`
2. 先让链只调用 `search_story_memory`：
   - 汇总为 `SceneMemoryContext`
3. 测试模型能否正确理解"哪些记忆会影响当前场景"
4. **验证**：确保记忆检索的准确性和相关性

### 阶段 4：scene_text_chain 接入记忆上下文
**目标**：将记忆整合到文本生成中

**实施步骤**：
1. 改造 `scene_text_chain`：
   - 接受 `SceneMemoryContext` 作为输入
   - 修改 Prompt，显式引用记忆上下文
2. 增加一致性测试：
   - 利用现有的 `test_consistency_check.py` 作为回归检查
3. **验证**：确保生成内容的一致性和连贯性提升

### 阶段 5：写作过程中的在线 function call（可选）
**目标**：支持在场景生成过程中动态查询状态

**实施步骤**：
1. 考虑引入 agent 型链：
   - 允许模型在一场戏内部写到一半还能查状态
2. 评估复杂度和收益：
   - 这一步复杂度高，需要谨慎评估
3. **验证**：确认动态查询确实提升了生成质量

## 技术实施要点

### 数据一致性策略
- **结构化数据**：使用事务保证一致性
- **向量数据**：允许最终一致性，定期同步
- **JSON 文件**：仍然是链间传递的主要方式

### 性能考虑
- **索引策略**：为常用查询字段建立索引
- **向量化策略**：按场景或段落分块，避免单个向量过长
- **缓存策略**：对频繁查询的状态数据进行缓存

### 错误处理
- **数据库不可用**：降级到仅使用 JSON 文件
- **向量检索失败**：使用关键词检索作为备选
- **数据不一致**：提供数据修复工具

## 下一步行动建议

1. **优先设计数据模型**：在 `models.py` 中定义核心 Pydantic 模型
2. **实现抽象层**：先完成 `runtime/db.py` 和 `runtime/vector_store.py` 的基础接口
3. **选择技术栈**：确定具体的数据库和向量库实现
4. **编写测试**：为每个阶段设计相应的测试用例

## 风险评估

### 技术风险
- **数据迁移**：从现有 JSON 文件迁移到数据库的复杂性
- **性能影响**：数据库查询可能影响生成速度
- **依赖增加**：引入新的外部依赖可能影响部署

### 缓解措施
- **渐进式迁移**：保持向后兼容，逐步切换
- **性能监控**：建立性能基准，持续优化
- **依赖隔离**：通过抽象层隔离具体实现

---

*本文档记录了数据库与向量库引入的整体设计方案，后续实施时请严格按照项目的模块化设计原则和 Pydantic 模型优先的规范。*
