# å¼€å‘è€…: jamesenh, å¼€å‘æ—¶é—´: 2025-11-17
# æ›´æ–°: 2025-11-25 - ç®€åŒ–è®°å¿†å±‚æ¶æ„ï¼Œç§»é™¤ SQLite å’Œç‹¬ç«‹ VectorStoreï¼Œç»Ÿä¸€ä½¿ç”¨ Mem0
# æ›´æ–°: 2025-11-30 - æ·»åŠ  cleanup æ–¹æ³•å’Œé€€å‡ºè°ƒè¯•æ—¥å¿—

"""
ç¼–æ’å™¨
åè°ƒæ•´ä¸ªå°è¯´ç”Ÿæˆæµç¨‹ï¼Œä½¿ç”¨ Mem0 ä½œä¸ºå”¯ä¸€çš„è®°å¿†å­˜å‚¨å±‚
"""
import os
import json
import time
import threading
from typing import Optional, List, Dict, Any

# è°ƒè¯•æ¨¡å¼å¼€å…³
DEBUG_EXIT = os.getenv("NOVELGEN_DEBUG", "0") == "1"


def _debug_log(msg: str):
    """è¾“å‡ºè°ƒè¯•æ—¥å¿—ï¼ˆä»…åœ¨ DEBUG_EXIT=True æ—¶ï¼‰"""
    if DEBUG_EXIT:
        timestamp = time.strftime("%H:%M:%S")
        thread_name = threading.current_thread().name
        print(f"[{timestamp}][{thread_name}] ğŸ” [orchestrator] {msg}")

from novelgen.models import (
    WorldSetting, ThemeConflict, CharactersConfig,
    Outline, ChapterPlan, GeneratedChapter, GeneratedScene,
    ChapterSummary, ChapterMemoryEntry, ConsistencyReport, RevisionStatus
)
from novelgen.config import ProjectConfig
from novelgen.runtime.exporter import export_chapter_to_txt, export_all_chapters_to_txt
from novelgen.runtime.memory import generate_chapter_memory_entry
from novelgen.runtime.workflow import (
    create_novel_generation_workflow, 
    get_default_recursion_limit,
    get_estimated_nodes_per_chapter
)
from novelgen.runtime.mem0_manager import Mem0Manager, is_shutdown_requested
from novelgen.models import NovelGenerationState
from datetime import datetime


class NovelOrchestrator:
    """å°è¯´ç”Ÿæˆç¼–æ’å™¨
    
    ä½¿ç”¨ Mem0 ä½œä¸ºå”¯ä¸€çš„è®°å¿†å±‚ï¼Œä¸å†æ”¯æŒ SQLite å’Œç‹¬ç«‹ VectorStore çš„é™çº§æ¨¡å¼
    """

    def __init__(self, project_name: str, base_dir: str = "projects", verbose: bool = False, show_prompt: bool = True):
        """åˆå§‹åŒ–ç¼–æ’å™¨

        Args:
            project_name: é¡¹ç›®åç§°
            base_dir: é¡¹ç›®åŸºç¡€ç›®å½•
            verbose: æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼ˆæ˜¾ç¤ºæç¤ºè¯ã€å“åº”æ—¶é—´ã€tokenä½¿ç”¨æƒ…å†µï¼‰
            show_prompt: verbose æ¨¡å¼ä¸‹æ˜¯å¦æ˜¾ç¤ºå®Œæ•´æç¤ºè¯ï¼ˆé»˜è®¤ Trueï¼‰

        Raises:
            RuntimeError: å¦‚æœ Mem0 æœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥
        """
        self.project_name = project_name
        self.project_dir = os.path.join(base_dir, project_name)
        self.config = ProjectConfig(project_dir=self.project_dir)
        self.verbose = verbose
        self.show_prompt = show_prompt

        # åˆ›å»ºé¡¹ç›®ç›®å½•
        os.makedirs(self.project_dir, exist_ok=True)
        os.makedirs(self.config.chapters_dir, exist_ok=True)

        # åˆå§‹åŒ– Mem0 ç®¡ç†å™¨ï¼ˆä½œä¸ºå”¯ä¸€çš„è®°å¿†å±‚ï¼‰
        self.mem0_manager: Optional[Mem0Manager] = None
        
        # æ£€æŸ¥ Mem0 é…ç½®
        if not hasattr(self.config, 'mem0_config') or not self.config.mem0_config:
            raise RuntimeError(
                "Mem0 é…ç½®æœªè®¾ç½®ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ MEM0_ENABLED=true å¹¶é…ç½®ç›¸å…³å‚æ•°ã€‚"
            )
        
        if not self.config.mem0_config.enabled:
            raise RuntimeError(
                "Mem0 æœªå¯ç”¨ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ MEM0_ENABLED=trueã€‚"
            )
        
        # åˆå§‹åŒ– Mem0
        try:
            from novelgen.runtime.mem0_manager import Mem0Manager, Mem0InitializationError
            self.mem0_manager = Mem0Manager(
                config=self.config.mem0_config,
                project_id=project_name,
                embedding_config=self.config.embedding_config
            )
            health = self.mem0_manager.health_check()
            if health["status"] == "healthy":
                print(f"âœ… Mem0 è®°å¿†å±‚å·²å¯ç”¨: {health['message']}")
            else:
                raise RuntimeError(f"Mem0 å¥åº·æ£€æŸ¥å¤±è´¥: {health['message']}")
        except Exception as e:
            raise RuntimeError(f"Mem0 åˆå§‹åŒ–å¤±è´¥: {e}") from e
        
        # åˆå§‹åŒ– LangGraph å·¥ä½œæµï¼ˆä½¿ç”¨ SQLite æŒä¹…åŒ–æ£€æŸ¥ç‚¹ï¼‰
        self.workflow = create_novel_generation_workflow(project_dir=self.project_dir)
        self._workflow_state: Optional[NovelGenerationState] = None
        print("âœ… LangGraph å·¥ä½œæµå·²åˆå§‹åŒ–ï¼ˆSQLite æŒä¹…åŒ–ï¼‰")

    def save_json(self, data, filepath: str):
        """ä¿å­˜JSONæ–‡ä»¶"""
        with open(filepath, 'w', encoding='utf-8') as f:
            if hasattr(data, 'model_dump'):
                json.dump(data.model_dump(), f, ensure_ascii=False, indent=2)
            else:
                json.dump(data, f, ensure_ascii=False, indent=2)

    def load_json(self, filepath: str, model_class=None):
        """åŠ è½½JSONæ–‡ä»¶"""
        if not os.path.exists(filepath):
            return None

        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if model_class:
            return model_class(**data)
        return data

    def _load_chapter_memory_entries(self) -> List[ChapterMemoryEntry]:
        """è¯»å–ç« èŠ‚è®°å¿†æ–‡ä»¶"""
        if not os.path.exists(self.config.chapter_memory_file):
            return []

        try:
            with open(self.config.chapter_memory_file, 'r', encoding='utf-8') as f:
                raw_entries = json.load(f)
        except json.JSONDecodeError as exc:
            print(f"âš ï¸ ç« èŠ‚è®°å¿†æ–‡ä»¶è§£æå¤±è´¥ï¼Œå°†å¿½ç•¥ï¼š{exc}")
            return []

        entries = []
        for item in raw_entries:
            try:
                entries.append(ChapterMemoryEntry(**item))
            except Exception as exc:
                print(f"âš ï¸ ç« èŠ‚è®°å¿†è®°å½•æ— æ•ˆï¼Œå·²è·³è¿‡: {exc}")
        return entries

    def _save_chapter_memory_entries(self, entries: List[ChapterMemoryEntry]):
        """å°†ç« èŠ‚è®°å¿†åˆ—è¡¨å†™å›ç£ç›˜"""
        serializable = [entry.model_dump() for entry in entries]
        self.save_json(serializable, self.config.chapter_memory_file)

    def _append_chapter_memory_entry(self, entry: ChapterMemoryEntry):
        """è¿½åŠ æˆ–æ›¿æ¢æŸç« èŠ‚çš„è®°å¿†è®°å½•"""
        entries = self._load_chapter_memory_entries()
        entries = [e for e in entries if e.chapter_number != entry.chapter_number]
        entries.append(entry)
        entries.sort(key=lambda e: e.chapter_number)
        self._save_chapter_memory_entries(entries)

    def _get_recent_chapter_memory(self, chapter_number: int, limit: Optional[int] = None) -> List[ChapterMemoryEntry]:
        """
        æŒ‰ç« èŠ‚ç¼–å·è¿‡æ»¤å¹¶è¿”å›æœ€è¿‘çš„è®°å¿†æ¡ç›®

        Args:
            chapter_number: å½“å‰ç« èŠ‚ç¼–å·
            limit: éœ€è¦çš„å†å²æ¡ç›®æ•°é‡
        """
        entries = [
            entry for entry in self._load_chapter_memory_entries()
            if entry.chapter_number < chapter_number
        ]
        entries.sort(key=lambda e: e.chapter_number, reverse=True)
        if limit is not None:
            entries = entries[:limit]
        return list(reversed(entries))

    def _format_memory_entries(self, entries: List[ChapterMemoryEntry]) -> str:
        """å°†è®°å¿†æ¡ç›®åˆ—è¡¨åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²"""
        if not entries:
            return "[]"
        payload = [entry.model_dump() for entry in entries]
        return json.dumps(payload, ensure_ascii=False, indent=2)

    def _build_chapter_context_payload(self, chapter_number: int) -> str:
        """æ ¹æ®ç« èŠ‚ç¼–å·æ„å»ºç”¨äºæç¤ºè¯çš„ä¸Šä¸‹æ–‡è½½è·"""
        recent_entries = self._get_recent_chapter_memory(
            chapter_number,
            limit=self.config.memory_context_chapters
        )
        return self._format_memory_entries(recent_entries)

    def _get_chapter_summary(self, chapter_number: int) -> Optional[ChapterSummary]:
        """ä»å¤§çº²ä¸­è·å–æŒ‡å®šç« èŠ‚çš„æ‘˜è¦"""
        outline = self.load_json(self.config.outline_file, Outline)
        if not outline:
            return None
        for chapter in outline.chapters:
            if chapter.chapter_number == chapter_number:
                return chapter
        return None

    def _ensure_chapter_dependencies_met(self, chapter_summary: ChapterSummary):
        """æ ¡éªŒç« èŠ‚ä¾èµ–çš„é€»è¾‘æœ‰æ•ˆæ€§ï¼ˆstep5é˜¶æ®µï¼‰"""
        if not chapter_summary or not chapter_summary.dependencies:
            return

        # step5é˜¶æ®µåªéªŒè¯é€»è¾‘æœ‰æ•ˆæ€§ï¼Œä¸éªŒè¯å®é™…æ»¡è¶³æƒ…å†µ
        for dep in chapter_summary.dependencies:
            if dep.chapter_number is None:
                continue
            if dep.chapter_number >= chapter_summary.chapter_number:
                raise ValueError(
                    f"ç« èŠ‚{chapter_summary.chapter_number}ä¾èµ–æ— æ•ˆï¼šä¸èƒ½ä¾èµ–æœªæ¥ç« èŠ‚{dep.chapter_number}"
                )

    def _ensure_chapter_dependencies_actually_met(self, chapter_summary: ChapterSummary):
        """æ ¡éªŒç« èŠ‚ä¾èµ–æ˜¯å¦å·²ç»ç”±æ—¢æœ‰ç« èŠ‚å†…å®¹æ»¡è¶³ï¼ˆstep6å¼€å§‹å‰ï¼‰"""
        if not chapter_summary or not chapter_summary.dependencies:
            return

        # æ£€æŸ¥å·²å®Œæˆçš„ç« èŠ‚å†…å®¹æ–‡ä»¶ï¼ˆä½¿ç”¨å®é™…ä¿å­˜çš„ç« èŠ‚JSONæ–‡ä»¶ï¼‰
        existing = set()
        for i in range(1, chapter_summary.chapter_number):
            content_file = os.path.join(
                self.config.chapters_dir,
                f"chapter_{i:03d}.json"
            )
            if os.path.exists(content_file):
                existing.add(i)
        
        unmet = []
        for dep in chapter_summary.dependencies:
            if dep.chapter_number is None or dep.chapter_number <= 0:
                continue
            if dep.chapter_number not in existing:
                unmet.append(f"ç« èŠ‚{dep.chapter_number} - {dep.description}")

        if unmet:
            raise ValueError(
                f"ç« èŠ‚{chapter_summary.chapter_number}å°šæœªæ»¡è¶³ä»¥ä¸‹ä¾èµ–ï¼š{'; '.join(unmet)}"
            )

    def _build_consistency_context(self, chapter_number: int, chapter_summary: Optional[ChapterSummary]) -> str:
        """ç»„åˆä¸€è‡´æ€§æ£€æµ‹æ‰€éœ€çš„ä¸Šä¸‹æ–‡ï¼ˆå¤§çº²+è®°å¿†ï¼‰"""
        recent_entries = self._get_recent_chapter_memory(
            chapter_number,
            limit=self.config.memory_context_chapters
        )
        payload = {
            "outline_summary": chapter_summary.model_dump() if chapter_summary else {},
            "recent_memory": [entry.model_dump() for entry in recent_entries]
        }
        return json.dumps(payload, ensure_ascii=False, indent=2)

    def _record_consistency_report(self, report: ConsistencyReport):
        """å°†ä¸€è‡´æ€§æ£€æµ‹ç»“æœé™„åŠ åˆ°é¡¹ç›®æŠ¥å‘Šæ–‡ä»¶"""
        data = []
        if os.path.exists(self.config.consistency_report_file):
            try:
                with open(self.config.consistency_report_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            except json.JSONDecodeError:
                data = []

        data.append(report.model_dump())
        with open(self.config.consistency_report_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def _save_entity_state(self, entity_type: str, entity_id: str, state_description: str, 
                          chapter_index: Optional[int] = None, scene_index: Optional[int] = None,
                          story_timeline: Optional[str] = None):
        """ä¿å­˜å®ä½“çŠ¶æ€åˆ° Mem0"""
        try:
            self.mem0_manager.add_entity_state(
                entity_id=entity_id,
                entity_type=entity_type,
                state_description=state_description,
                chapter_index=chapter_index,
                scene_index=scene_index,
                story_timeline=story_timeline,
            )
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å®ä½“çŠ¶æ€åˆ° Mem0 å¤±è´¥: {e}")
    
    def _save_scene_content(self, content: str, chapter_index: int, scene_index: int, 
                           content_type: str = "scene"):
        """ä¿å­˜åœºæ™¯å†…å®¹åˆ° Mem0"""
        try:
            chunks = self.mem0_manager.add_scene_content(
                content=content,
                chapter_index=chapter_index,
                scene_index=scene_index,
                content_type=content_type
            )
            if chunks:
                print(f"    å·²å°†åœºæ™¯{scene_index}å†…å®¹ä¿å­˜åˆ° Mem0ï¼ˆ{len(chunks)}ä¸ªå—ï¼‰")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜åœºæ™¯å†…å®¹åˆ° Mem0 å¤±è´¥: {e}")
    
    def _delete_chapter_memory(self, chapter_index: int):
        """åˆ é™¤æŒ‡å®šç« èŠ‚çš„æ‰€æœ‰åœºæ™¯è®°å¿†"""
        try:
            self.mem0_manager.delete_chapter_memory(chapter_index)
            print(f"å·²åˆ é™¤ç¬¬{chapter_index}ç« çš„åœºæ™¯è®°å¿†")
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤ç« èŠ‚è®°å¿†å¤±è´¥: {e}")
    
    def _get_or_create_workflow_state(self) -> NovelGenerationState:
        """è·å–æˆ–åˆ›å»ºå·¥ä½œæµçŠ¶æ€

        ä»é¡¹ç›®ç›®å½•åŠ è½½å·²å­˜åœ¨çš„ JSON æ–‡ä»¶ï¼Œå¹¶æ ¹æ®æ–‡ä»¶å­˜åœ¨æ€§æ¨æ–­ completed_stepsã€‚
        è¿™æ ·åœ¨é‡æ–°è¿è¡Œæ—¶ï¼Œå·¥ä½œæµèƒ½å¤Ÿæ­£ç¡®è·³è¿‡å·²å®Œæˆçš„æ­¥éª¤ã€‚

        æ›´æ–°: 2025-11-27 - æ·»åŠ  completed_steps æ¨æ–­é€»è¾‘ï¼Œä¿®å¤æ£€æŸ¥ç‚¹æ¢å¤é—®é¢˜
        """
        if self._workflow_state is None:
            # ä» JSON æ–‡ä»¶åŠ è½½ç°æœ‰æ•°æ®
            from novelgen.models import Settings

            # ä» settings.json æ–‡ä»¶åŠ è½½é…ç½®
            settings_file = os.path.join(self.project_dir, "settings.json")
            settings = self.load_json(settings_file, Settings)
            if settings is None:
                raise ValueError(f"settings.json ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥: {settings_file}")

            world = self.load_json(self.config.world_file, WorldSetting)
            theme_conflict = self.load_json(self.config.theme_conflict_file, ThemeConflict)
            characters = self.load_json(self.config.characters_file, CharactersConfig)
            outline = self.load_json(self.config.outline_file, Outline)

            # åŠ è½½ç« èŠ‚è®¡åˆ’å’Œç”Ÿæˆçš„ç« èŠ‚
            chapters_plan = {}
            chapters = {}
            if outline:
                for ch_summary in outline.chapters:
                    num = ch_summary.chapter_number
                    plan_file = os.path.join(self.config.chapters_dir, f"chapter_{num:03d}_plan.json")
                    if os.path.exists(plan_file):
                        chapters_plan[num] = self.load_json(plan_file, ChapterPlan)

                    chapter_file = os.path.join(self.config.chapters_dir, f"chapter_{num:03d}.json")
                    if os.path.exists(chapter_file):
                        chapters[num] = self.load_json(chapter_file, GeneratedChapter)

            # åŠ è½½ç« èŠ‚è®°å¿†
            chapter_memories = self._load_chapter_memory_entries()

            # æ ¹æ®å·²å­˜åœ¨çš„æ–‡ä»¶æ¨æ–­ completed_steps
            # è¿™æ˜¯æ£€æŸ¥ç‚¹æ¢å¤çš„å…³é”®ï¼šç¡®ä¿é‡æ–°è¿è¡Œæ—¶èƒ½æ­£ç¡®è·³è¿‡å·²å®Œæˆçš„æ­¥éª¤
            completed_steps = self._infer_completed_steps(
                settings=settings,
                world=world,
                theme_conflict=theme_conflict,
                characters=characters,
                outline=outline,
                chapters_plan=chapters_plan,
                chapters=chapters
            )

            if completed_steps:
                print(f"ğŸ“‹ æ£€æµ‹åˆ°å·²å®Œæˆçš„æ­¥éª¤: {', '.join(completed_steps)}")

            # è·å–é€’å½’é™åˆ¶é…ç½®
            recursion_limit = get_default_recursion_limit()
            
            self._workflow_state = NovelGenerationState(
                project_name=self.project_name,
                project_dir=self.project_dir,
                settings=settings,
                world=world,
                theme_conflict=theme_conflict,
                characters=characters,
                outline=outline,
                chapters_plan=chapters_plan,
                chapters=chapters,
                chapter_memories=chapter_memories,
                completed_steps=completed_steps,
                verbose=self.verbose,  # ä¼ é€’ verbose å‚æ•°åˆ°å·¥ä½œæµçŠ¶æ€
                show_prompt=self.show_prompt,  # ä¼ é€’ show_prompt å‚æ•°åˆ°å·¥ä½œæµçŠ¶æ€
                # é€’å½’é™åˆ¶é¢„ä¼°æœºåˆ¶ç›¸å…³å­—æ®µ
                recursion_limit=recursion_limit,
                node_execution_count=0,  # åˆå§‹åŒ–ä¸º 0
                should_stop_early=False
                # æ³¨æ„ï¼šmem0_manager ä¸æ”¾å…¥çŠ¶æ€ï¼Œå› ä¸ºå®ƒæ— æ³•è¢« msgpack åºåˆ—åŒ–
                # åœ¨ orchestrator çº§åˆ«é€šè¿‡ self.mem0_manager ç®¡ç†
            )

        return self._workflow_state

    def _infer_completed_steps(
        self,
        settings,
        world,
        theme_conflict,
        characters,
        outline,
        chapters_plan: dict,
        chapters: dict
    ) -> list:
        """æ ¹æ®å·²å­˜åœ¨çš„æ•°æ®æ¨æ–­ completed_steps åˆ—è¡¨

        éµå¾ªå·¥ä½œæµçš„æ‰§è¡Œé¡ºåºï¼š
        1. load_settings
        2. world_creation
        3. theme_conflict_creation
        4. character_creation
        5. outline_creation
        6. chapter_planning
        7. init_chapter_loop
        8. chapter_generation_N (æ¯ä¸ªç« èŠ‚)
        9. consistency_check_N (æ¯ä¸ªç« èŠ‚)

        Args:
            settings: é¡¹ç›®é…ç½®
            world: ä¸–ç•Œè§‚è®¾å®š
            theme_conflict: ä¸»é¢˜å†²çª
            characters: è§’è‰²é…ç½®
            outline: å¤§çº²
            chapters_plan: ç« èŠ‚è®¡åˆ’å­—å…¸
            chapters: å·²ç”Ÿæˆç« èŠ‚å­—å…¸

        Returns:
            æ¨æ–­å‡ºçš„å·²å®Œæˆæ­¥éª¤åˆ—è¡¨
        """
        completed_steps = []

        # æŒ‰ç…§å·¥ä½œæµé¡ºåºæ¨æ–­
        if settings is not None:
            completed_steps.append("load_settings")

        if world is not None:
            completed_steps.append("world_creation")

        if theme_conflict is not None:
            completed_steps.append("theme_conflict_creation")

        if characters is not None:
            completed_steps.append("character_creation")

        if outline is not None:
            completed_steps.append("outline_creation")

        # æ£€æŸ¥ç« èŠ‚è®¡åˆ’æ˜¯å¦å®Œæ•´ï¼ˆæ‰€æœ‰ç« èŠ‚éƒ½æœ‰è®¡åˆ’ï¼‰
        if outline and chapters_plan:
            expected_chapters = {ch.chapter_number for ch in outline.chapters}
            existing_plans = set(chapters_plan.keys())
            if expected_chapters <= existing_plans:
                completed_steps.append("chapter_planning")
                completed_steps.append("init_chapter_loop")

        # æ¨æ–­å·²å®Œæˆçš„ç« èŠ‚ç”Ÿæˆå’Œä¸€è‡´æ€§æ£€æŸ¥
        for chapter_num in sorted(chapters.keys()):
            chapter = chapters[chapter_num]
            # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼ˆè‡³å°‘æœ‰ä¸€ä¸ªåœºæ™¯ï¼‰
            if chapter.scenes and len(chapter.scenes) > 0:
                completed_steps.append(f"chapter_generation_{chapter_num}")
                # å‡è®¾ç”Ÿæˆåéƒ½åšäº†ä¸€è‡´æ€§æ£€æŸ¥
                completed_steps.append(f"consistency_check_{chapter_num}")

        return completed_steps
    
    def run_workflow(self, stop_at: Optional[str] = None) -> NovelGenerationState:
        """"è¿è¡Œå®Œæ•´å·¥ä½œæµ
        
        Args:
            stop_at: å¯é€‰çš„åœæ­¢èŠ‚ç‚¹åç§°ï¼ˆå¦‚ "world_creation", "outline_creation" ç­‰ï¼‰
        
        Returns:
            æœ€ç»ˆçš„å·¥ä½œæµçŠ¶æ€
        """
        print("ğŸš€ å¼€å§‹è¿è¡Œ LangGraph å·¥ä½œæµ...")
        
        # è·å–åˆå§‹çŠ¶æ€
        initial_state = self._get_or_create_workflow_state()
        
        # é…ç½®å·¥ä½œæµæ‰§è¡Œ
        # æ›´æ–°: 2025-11-30 - ä»çŠ¶æ€ä¸­è¯»å– recursion_limit å¹¶ä¼ å…¥ config
        recursion_limit = initial_state.recursion_limit if initial_state else get_default_recursion_limit()
        config = {
            "configurable": {"thread_id": self.project_name},
            "recursion_limit": recursion_limit
        }
        print(f"   é€’å½’é™åˆ¶: {recursion_limit}, æ¯ç« é¢„ä¼°èŠ‚ç‚¹æ•°: {get_estimated_nodes_per_chapter()}")
        
        # è¿è¡Œå·¥ä½œæµ
        final_state = None
        interrupted = False
        for state in self.workflow.stream(initial_state, config):
            # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°åœæ­¢ä¿¡å·
            if is_shutdown_requested():
                print("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œå·¥ä½œæµä¸­æ–­")
                interrupted = True
                break
            
            # state æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«èŠ‚ç‚¹åç§°å’Œå¯¹åº”çš„çŠ¶æ€æ›´æ–°
            for node_name, node_output in state.items():
                print(f"  âœ“ èŠ‚ç‚¹ '{node_name}' æ‰§è¡Œå®Œæˆ")
                final_state = node_output
                
                # å¦‚æœæŒ‡å®šäº†åœæ­¢èŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦åˆ°è¾¾
                if stop_at and node_name == stop_at:
                    print(f"â¸ï¸  å·²åˆ°è¾¾åœæ­¢èŠ‚ç‚¹ '{stop_at}'ï¼Œå·¥ä½œæµæš‚åœ")
                    self._workflow_state = final_state
                    return final_state
        
        if interrupted:
            print("â¹ï¸ å·¥ä½œæµå·²è¢«ç”¨æˆ·ä¸­æ–­")
            self._workflow_state = final_state
            raise KeyboardInterrupt("ç”¨æˆ·ä¸­æ–­å·¥ä½œæµ")
        
        print("âœ… LangGraph å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        self._workflow_state = final_state
        return final_state
    
    def resume_workflow(self, checkpoint_id: Optional[str] = None) -> NovelGenerationState:
        """ä»æ£€æŸ¥ç‚¹æ¢å¤å·¥ä½œæµ
        
        ä¿®å¤: 2025-11-30 - åœ¨æ¢å¤å‰åŒæ­¥æ–‡ä»¶ç³»ç»ŸçŠ¶æ€ï¼Œç¡®ä¿åœºæ™¯æ–‡ä»¶èƒ½æ­£ç¡®åˆå¹¶ä¸ºç« èŠ‚
        
        Args:
            checkpoint_id: æ£€æŸ¥ç‚¹ IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æœ€æ–°æ£€æŸ¥ç‚¹ï¼‰
        
        Returns:
            æ¢å¤åçš„å·¥ä½œæµçŠ¶æ€
        """
        print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤å·¥ä½œæµ...")
        
        # å…³é”®ä¿®å¤ï¼šå…ˆæ£€æŸ¥å¹¶åˆå¹¶æœªå®Œæˆçš„ç« èŠ‚ï¼ˆä»åœºæ™¯æ–‡ä»¶ï¼‰
        # è¿™å¤„ç†äº†åœºæ™¯éƒ½ç”Ÿæˆäº†ä½†ç« èŠ‚æ–‡ä»¶æœªä¿å­˜çš„æƒ…å†µ
        self._merge_incomplete_chapters_from_scenes()
        
        # é…ç½®å·¥ä½œæµæ‰§è¡Œ
        # æ›´æ–°: 2025-11-30 - ä»çŠ¶æ€ä¸­è¯»å– recursion_limit å¹¶ä¼ å…¥ config
        recursion_limit = get_default_recursion_limit()
        config = {
            "configurable": {"thread_id": self.project_name},
            "recursion_limit": recursion_limit
        }
        print(f"   é€’å½’é™åˆ¶: {recursion_limit}")
        
        # è·å–æ£€æŸ¥ç‚¹å†å²
        checkpoints = list(self.workflow.get_state_history(config))
        if not checkpoints:
            print("âš ï¸ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œå°†ä»å¤´å¼€å§‹è¿è¡Œ")
            return self.run_workflow()
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(checkpoints)} ä¸ªæ£€æŸ¥ç‚¹")
        
        # ä½¿ç”¨æœ€æ–°çš„æ£€æŸ¥ç‚¹æ¢å¤
        latest_checkpoint = checkpoints[0]
        print(f"  æ¢å¤æ£€æŸ¥ç‚¹: {latest_checkpoint.config['configurable']['thread_id']}")
        
        # å…³é”®ä¿®å¤ï¼šä»æ–‡ä»¶ç³»ç»ŸåŠ è½½æœ€æ–°çŠ¶æ€ï¼Œä¸æ£€æŸ¥ç‚¹çŠ¶æ€åŒæ­¥
        # è¿™ç¡®ä¿äº†åœ¨ä¸­æ–­åæ–°ç”Ÿæˆçš„æ–‡ä»¶ï¼ˆå¦‚åœºæ™¯æ–‡ä»¶ï¼‰èƒ½è¢«æ­£ç¡®è¯†åˆ«
        file_state = self._get_or_create_workflow_state()
        
        # è·å–æ£€æŸ¥ç‚¹ä¸­çš„çŠ¶æ€
        checkpoint_state = latest_checkpoint.values
        
        # åŒæ­¥æ–‡ä»¶ç³»ç»ŸçŠ¶æ€åˆ°æ£€æŸ¥ç‚¹ï¼ˆæ–‡ä»¶ç³»ç»ŸçŠ¶æ€ä¼˜å…ˆï¼Œå› ä¸ºå®ƒåæ˜ å®é™…ç”Ÿæˆçš„å†…å®¹ï¼‰
        state_updates = self._sync_file_state_to_checkpoint(file_state, checkpoint_state)
        
        if state_updates:
            print(f"ğŸ“‚ åŒæ­¥æ–‡ä»¶ç³»ç»ŸçŠ¶æ€: {list(state_updates.keys())}")
            # ä½¿ç”¨ update_state æ›´æ–°æ£€æŸ¥ç‚¹çŠ¶æ€
            self.workflow.update_state(config, state_updates)
        
        # ä»æ£€æŸ¥ç‚¹ç»§ç»­æ‰§è¡Œ
        final_state = None
        interrupted = False
        for state in self.workflow.stream(None, config):
            # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°åœæ­¢ä¿¡å·
            if is_shutdown_requested():
                print("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œå·¥ä½œæµä¸­æ–­")
                interrupted = True
                break
            
            for node_name, node_output in state.items():
                print(f"  âœ“ èŠ‚ç‚¹ '{node_name}' æ‰§è¡Œå®Œæˆ")
                final_state = node_output
        
        if interrupted:
            print("â¹ï¸ å·¥ä½œæµå·²è¢«ç”¨æˆ·ä¸­æ–­")
            self._workflow_state = final_state
            raise KeyboardInterrupt("ç”¨æˆ·ä¸­æ–­å·¥ä½œæµ")
        
        # æ£€æŸ¥æ˜¯å¦çœŸçš„å®Œæˆäº†æ‰€æœ‰å·¥ä½œ
        # å¦‚æœ final_state æ˜¯ Noneï¼ˆå·¥ä½œæµè®¤ä¸ºå·²ç»ç»“æŸï¼‰ï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ç« èŠ‚
        if final_state is None:
            print("âš ï¸ æ£€æŸ¥ç‚¹æ˜¾ç¤ºå·¥ä½œæµå·²ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ç« èŠ‚...")
            incomplete_chapters = self._check_incomplete_chapters()
            
            if incomplete_chapters:
                print(f"ğŸ” å‘ç° {len(incomplete_chapters)} ä¸ªæœªå®Œæˆçš„ç« èŠ‚: {incomplete_chapters}")
                print("ğŸ“ æ£€æŸ¥ç‚¹çŠ¶æ€å·²æŸåï¼Œå°†é‡æ–°è¿è¡Œå·¥ä½œæµï¼ˆè·³è¿‡å·²å®Œæˆç« èŠ‚ï¼‰...")
                
                # é‡ç½®æ£€æŸ¥ç‚¹ï¼Œä½¿ç”¨æ–‡ä»¶ç³»ç»ŸçŠ¶æ€é‡æ–°å¼€å§‹
                # å…ˆåˆå¹¶å·²æœ‰çš„åœºæ™¯æ–‡ä»¶
                self._merge_incomplete_chapters_from_scenes()
                
                # é‡æ–°è·å–çŠ¶æ€å¹¶è¿è¡Œ
                return self.run_workflow()
            else:
                print("âœ… æ‰€æœ‰ç« èŠ‚å·²å®Œæˆ")
                # è¿”å›æ–‡ä»¶ç³»ç»ŸçŠ¶æ€
                final_state = self._get_or_create_workflow_state()
        
        print("âœ… å·¥ä½œæµæ¢å¤æ‰§è¡Œå®Œæˆ")
        self._workflow_state = final_state
        return final_state
    
    def _check_incomplete_chapters(self) -> List[int]:
        """æ£€æŸ¥æœ‰å“ªäº›ç« èŠ‚æœªå®Œæˆ
        
        æ ¹æ®æ–‡ä»¶ç³»ç»ŸçŠ¶æ€æ£€æµ‹ï¼š
        1. ç« èŠ‚è®¡åˆ’å­˜åœ¨ä½†ç« èŠ‚JSONä¸å­˜åœ¨
        2. åœºæ™¯æ–‡ä»¶æ•°é‡å°‘äºè®¡åˆ’çš„åœºæ™¯æ•°
        
        Returns:
            æœªå®Œæˆçš„ç« èŠ‚ç¼–å·åˆ—è¡¨
        """
        import os
        import json
        
        chapters_dir = os.path.join(self.project_dir, "chapters")
        if not os.path.exists(chapters_dir):
            return []
        
        incomplete = []
        
        # æ‰«ææ‰€æœ‰ç« èŠ‚è®¡åˆ’
        for filename in os.listdir(chapters_dir):
            if not filename.endswith("_plan.json"):
                continue
            
            # æå–ç« èŠ‚å·
            try:
                ch_num = int(filename.split("_")[1])
            except (IndexError, ValueError):
                continue
            
            # æ£€æŸ¥ç« èŠ‚JSONæ˜¯å¦å­˜åœ¨
            chapter_file = os.path.join(chapters_dir, f"chapter_{ch_num:03d}.json")
            if not os.path.exists(chapter_file):
                # ç« èŠ‚JSONä¸å­˜åœ¨ï¼Œæ£€æŸ¥åœºæ™¯æ–‡ä»¶
                plan_file = os.path.join(chapters_dir, filename)
                try:
                    with open(plan_file, 'r', encoding='utf-8') as f:
                        plan_data = json.load(f)
                    expected_scenes = len(plan_data.get("scenes", []))
                except Exception:
                    expected_scenes = 0
                
                # ç»Ÿè®¡å·²æœ‰çš„åœºæ™¯æ–‡ä»¶
                scene_files = [f for f in os.listdir(chapters_dir) 
                              if f.startswith(f"scene_{ch_num:03d}_") and f.endswith(".json")]
                actual_scenes = len(scene_files)
                
                if actual_scenes < expected_scenes:
                    incomplete.append(ch_num)
                    print(f"    ç¬¬{ch_num}ç« : {actual_scenes}/{expected_scenes} åœºæ™¯")
        
        return sorted(incomplete)
    
    def _sync_file_state_to_checkpoint(
        self, 
        file_state: NovelGenerationState, 
        checkpoint_state: dict
    ) -> dict:
        """åŒæ­¥æ–‡ä»¶ç³»ç»ŸçŠ¶æ€åˆ°æ£€æŸ¥ç‚¹çŠ¶æ€
        
        æ¯”è¾ƒæ–‡ä»¶ç³»ç»ŸçŠ¶æ€å’Œæ£€æŸ¥ç‚¹çŠ¶æ€ï¼Œè¿”å›éœ€è¦æ›´æ–°çš„å­—æ®µã€‚
        æ–‡ä»¶ç³»ç»ŸçŠ¶æ€ä¼˜å…ˆï¼Œå› ä¸ºå®ƒåæ˜ å®é™…ç”Ÿæˆçš„å†…å®¹ã€‚
        
        å…³é”®åœºæ™¯ï¼š
        - åœºæ™¯æ–‡ä»¶å·²ç”Ÿæˆä½† chapter_XXX.json æœªä¿å­˜
        - ä¸­æ–­åæ–‡ä»¶ç³»ç»Ÿæœ‰æ–°å†…å®¹ä½†æ£€æŸ¥ç‚¹æœªæ›´æ–°
        
        Args:
            file_state: ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½çš„çŠ¶æ€
            checkpoint_state: æ£€æŸ¥ç‚¹ä¸­çš„çŠ¶æ€
            
        Returns:
            éœ€è¦æ›´æ–°çš„çŠ¶æ€å­—æ®µå­—å…¸
        """
        updates = {}
        
        # åŒæ­¥ chaptersï¼šç¡®ä¿å·²ç”Ÿæˆçš„ç« èŠ‚è¢«è¯†åˆ«
        file_chapters = file_state.chapters or {}
        checkpoint_chapters = checkpoint_state.get("chapters", {}) or {}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ç³»ç»Ÿä¸­å­˜åœ¨ä½†æ£€æŸ¥ç‚¹ä¸­ç¼ºå¤±çš„ç« èŠ‚
        for chapter_num, chapter in file_chapters.items():
            if chapter_num not in checkpoint_chapters:
                if "chapters" not in updates:
                    updates["chapters"] = dict(checkpoint_chapters)
                updates["chapters"][chapter_num] = chapter
                print(f"  ğŸ“– å‘ç°æ–°ç« èŠ‚: ç¬¬ {chapter_num} ç« ")
        
        # åŒæ­¥ chapters_planï¼šç¡®ä¿å·²ç”Ÿæˆçš„ç« èŠ‚è®¡åˆ’è¢«è¯†åˆ«
        file_plans = file_state.chapters_plan or {}
        checkpoint_plans = checkpoint_state.get("chapters_plan", {}) or {}
        
        for plan_num, plan in file_plans.items():
            if plan_num not in checkpoint_plans:
                if "chapters_plan" not in updates:
                    updates["chapters_plan"] = dict(checkpoint_plans)
                updates["chapters_plan"][plan_num] = plan
                print(f"  ğŸ“‹ å‘ç°æ–°ç« èŠ‚è®¡åˆ’: ç¬¬ {plan_num} ç« ")
        
        # åŒæ­¥åŸºç¡€æ•°æ®ï¼ˆworld, theme_conflict, characters, outlineï¼‰
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ä½†æ£€æŸ¥ç‚¹ä¸­ä¸ºç©º
        if file_state.world and not checkpoint_state.get("world"):
            updates["world"] = file_state.world
            print(f"  ğŸŒ åŒæ­¥ä¸–ç•Œè§‚")
        
        if file_state.theme_conflict and not checkpoint_state.get("theme_conflict"):
            updates["theme_conflict"] = file_state.theme_conflict
            print(f"  ğŸ­ åŒæ­¥ä¸»é¢˜å†²çª")
        
        if file_state.characters and not checkpoint_state.get("characters"):
            updates["characters"] = file_state.characters
            print(f"  ğŸ‘¥ åŒæ­¥è§’è‰²é…ç½®")
        
        if file_state.outline and not checkpoint_state.get("outline"):
            updates["outline"] = file_state.outline
            print(f"  ğŸ“‘ åŒæ­¥å¤§çº²")
        
        # åŒæ­¥ completed_stepsï¼šåŸºäºæ–‡ä»¶çŠ¶æ€æ›´æ–°å·²å®Œæˆæ­¥éª¤
        file_completed = set(file_state.completed_steps or [])
        checkpoint_completed = set(checkpoint_state.get("completed_steps", []) or [])
        
        new_completed = file_completed - checkpoint_completed
        if new_completed:
            updates["completed_steps"] = list(file_completed | checkpoint_completed)
            print(f"  âœ… åŒæ­¥å·²å®Œæˆæ­¥éª¤: {new_completed}")
        
        return updates
    
    def _merge_incomplete_chapters_from_scenes(self) -> None:
        """æ£€æŸ¥å¹¶åˆå¹¶æœªå®Œæˆçš„ç« èŠ‚ï¼ˆä»åœºæ™¯æ–‡ä»¶ï¼‰
        
        éå†é¡¹ç›®ç›®å½•ï¼ŒæŸ¥æ‰¾å­˜åœ¨åœºæ™¯æ–‡ä»¶ä½†ç¼ºå°‘ç« èŠ‚æ–‡ä»¶çš„æƒ…å†µï¼Œ
        è‡ªåŠ¨åˆå¹¶åœºæ™¯ä¸ºå®Œæ•´ç« èŠ‚ã€‚
        
        è¿™æ˜¯ä¸€ä¸ªé¢å¤–çš„å®‰å…¨æªæ–½ï¼Œç¡®ä¿å³ä½¿æ£€æŸ¥ç‚¹åŒæ­¥å¤±è´¥ï¼Œ
        åœºæ™¯æ–‡ä»¶ä¹Ÿèƒ½è¢«æ­£ç¡®åˆå¹¶ã€‚
        
        å¼€å‘è€…: jamesenh, å¼€å‘æ—¶é—´: 2025-11-30
        """
        import re
        
        if not os.path.exists(self.config.chapters_dir):
            return
        
        # æ‰«æåœºæ™¯æ–‡ä»¶ï¼ŒæŒ‰ç« èŠ‚åˆ†ç»„
        scene_pattern = re.compile(r"scene_(\d{3})_(\d{3})\.json")
        scenes_by_chapter: Dict[int, List[int]] = {}
        
        for filename in os.listdir(self.config.chapters_dir):
            match = scene_pattern.match(filename)
            if match:
                chapter_num = int(match.group(1))
                scene_num = int(match.group(2))
                if chapter_num not in scenes_by_chapter:
                    scenes_by_chapter[chapter_num] = []
                scenes_by_chapter[chapter_num].append(scene_num)
        
        # åŠ è½½å¤§çº²ä»¥è·å–ç« èŠ‚è®¡åˆ’
        outline = self.load_json(self.config.outline_file, Outline)
        if not outline:
            return
        
        # æ£€æŸ¥æ¯ä¸ªæœ‰åœºæ™¯æ–‡ä»¶çš„ç« èŠ‚
        for chapter_num, scene_nums in scenes_by_chapter.items():
            chapter_file = os.path.join(
                self.config.chapters_dir, 
                f"chapter_{chapter_num:03d}.json"
            )
            
            # å¦‚æœç« èŠ‚æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡
            if os.path.exists(chapter_file):
                continue
            
            # åŠ è½½ç« èŠ‚è®¡åˆ’
            plan_file = os.path.join(
                self.config.chapters_dir,
                f"chapter_{chapter_num:03d}_plan.json"
            )
            if not os.path.exists(plan_file):
                continue
            
            plan = self.load_json(plan_file, ChapterPlan)
            if not plan:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åœºæ™¯éƒ½å·²ç”Ÿæˆ
            expected_scenes = {s.scene_number for s in plan.scenes}
            existing_scenes = set(scene_nums)
            
            if expected_scenes <= existing_scenes:
                # æ‰€æœ‰åœºæ™¯éƒ½å­˜åœ¨ï¼Œåˆå¹¶ä¸ºç« èŠ‚
                print(f"ğŸ”§ å‘ç°æœªåˆå¹¶çš„ç« èŠ‚: ç¬¬ {chapter_num} ç« ï¼Œæ­£åœ¨åˆå¹¶...")
                
                scenes = []
                for scene_plan in plan.scenes:
                    scene_file = os.path.join(
                        self.config.chapters_dir,
                        f"scene_{chapter_num:03d}_{scene_plan.scene_number:03d}.json"
                    )
                    scene = self.load_json(scene_file, GeneratedScene)
                    if scene:
                        scenes.append(scene)
                
                if scenes:
                    chapter = GeneratedChapter(
                        chapter_number=chapter_num,
                        chapter_title=plan.chapter_title,
                        scenes=scenes,
                        total_words=sum(s.word_count for s in scenes)
                    )
                    self.save_json(chapter, chapter_file)
                    print(f"  âœ… ç¬¬ {chapter_num} ç« å·²åˆå¹¶: {chapter_file}")
    
    def close(self):
        """å…³é—­èµ„æºï¼ˆé¢„ç•™æ¥å£ï¼ŒMem0 ä¸éœ€è¦æ˜¾å¼å…³é—­ï¼‰"""
        pass

    # ==================== çŠ¶æ€æŸ¥è¯¢å’Œå›æ»šæ–¹æ³• ====================
    # å¼€å‘è€…: jamesenh, å¼€å‘æ—¶é—´: 2025-11-30
    
    def get_project_state(self) -> Dict[str, Any]:
        """è·å–é¡¹ç›®å®Œæ•´çŠ¶æ€
        
        ç”¨äº CLI å±•ç¤ºé¡¹ç›®å½“å‰è¿›åº¦å’Œå¯å›æ»šç‚¹
        
        Returns:
            åŒ…å«ä»¥ä¸‹ç»“æ„çš„å­—å…¸ï¼š
            {
                "steps": {
                    "world": {"exists": True, "file": "world.json"},
                    "theme_conflict": {"exists": True, "file": "theme_conflict.json"},
                    "characters": {"exists": True, "file": "characters.json"},
                    "outline": {"exists": True, "file": "outline.json", "chapters": 12},
                },
                "chapters": {
                    1: {"plan": True, "scenes": [1,2,3,4], "complete": True, "word_count": 3200},
                    2: {"plan": True, "scenes": [1,2,3], "complete": False},
                    3: {"plan": True, "scenes": [], "complete": False},
                },
                "checkpoint_exists": True
            }
        """
        import re
        
        state = {
            "steps": {},
            "chapters": {},
            "checkpoint_exists": False
        }
        
        # æ£€æŸ¥åŸºç¡€æ­¥éª¤æ–‡ä»¶
        state["steps"]["world"] = {
            "exists": os.path.exists(self.config.world_file),
            "file": "world.json"
        }
        state["steps"]["theme_conflict"] = {
            "exists": os.path.exists(self.config.theme_conflict_file),
            "file": "theme_conflict.json"
        }
        state["steps"]["characters"] = {
            "exists": os.path.exists(self.config.characters_file),
            "file": "characters.json"
        }
        
        outline_exists = os.path.exists(self.config.outline_file)
        state["steps"]["outline"] = {
            "exists": outline_exists,
            "file": "outline.json",
            "chapters": 0
        }
        
        if outline_exists:
            outline = self.load_json(self.config.outline_file, Outline)
            if outline:
                state["steps"]["outline"]["chapters"] = len(outline.chapters)
        
        # æ£€æŸ¥æ£€æŸ¥ç‚¹æ•°æ®åº“
        checkpoint_db = os.path.join(self.project_dir, "workflow_checkpoints.db")
        state["checkpoint_exists"] = os.path.exists(checkpoint_db)
        
        # æ£€æŸ¥ç« èŠ‚çŠ¶æ€
        if os.path.exists(self.config.chapters_dir):
            # æ”¶é›†æ‰€æœ‰ç« èŠ‚è®¡åˆ’
            plan_pattern = re.compile(r"chapter_(\d{3})_plan\.json")
            # æ”¶é›†æ‰€æœ‰åœºæ™¯æ–‡ä»¶
            scene_pattern = re.compile(r"scene_(\d{3})_(\d{3})\.json")
            # æ”¶é›†æ‰€æœ‰ç« èŠ‚æ–‡ä»¶
            chapter_pattern = re.compile(r"chapter_(\d{3})\.json")
            
            plans = {}
            scenes_by_chapter: Dict[int, List[int]] = {}
            completed_chapters = {}
            
            for filename in os.listdir(self.config.chapters_dir):
                # ç« èŠ‚è®¡åˆ’
                plan_match = plan_pattern.match(filename)
                if plan_match:
                    chapter_num = int(plan_match.group(1))
                    plan_file = os.path.join(self.config.chapters_dir, filename)
                    plan = self.load_json(plan_file, ChapterPlan)
                    if plan:
                        plans[chapter_num] = len(plan.scenes)
                    continue
                
                # åœºæ™¯æ–‡ä»¶
                scene_match = scene_pattern.match(filename)
                if scene_match:
                    chapter_num = int(scene_match.group(1))
                    scene_num = int(scene_match.group(2))
                    if chapter_num not in scenes_by_chapter:
                        scenes_by_chapter[chapter_num] = []
                    scenes_by_chapter[chapter_num].append(scene_num)
                    continue
                
                # å®Œæ•´ç« èŠ‚æ–‡ä»¶
                chapter_match = chapter_pattern.match(filename)
                if chapter_match:
                    chapter_num = int(chapter_match.group(1))
                    chapter_file = os.path.join(self.config.chapters_dir, filename)
                    chapter = self.load_json(chapter_file, GeneratedChapter)
                    if chapter:
                        completed_chapters[chapter_num] = {
                            "word_count": chapter.total_words,
                            "scene_count": len(chapter.scenes)
                        }
            
            # æ„å»ºç« èŠ‚çŠ¶æ€
            all_chapter_nums = set(plans.keys()) | set(scenes_by_chapter.keys()) | set(completed_chapters.keys())
            
            for ch_num in sorted(all_chapter_nums):
                chapter_state = {
                    "plan": ch_num in plans,
                    "plan_scenes": plans.get(ch_num, 0),
                    "scenes": sorted(scenes_by_chapter.get(ch_num, [])),
                    "complete": ch_num in completed_chapters,
                    "word_count": completed_chapters.get(ch_num, {}).get("word_count", 0)
                }
                state["chapters"][ch_num] = chapter_state
        
        return state
    
    def _delete_checkpoint_db(self) -> bool:
        """åˆ é™¤ LangGraph æ£€æŸ¥ç‚¹æ•°æ®åº“
        
        åˆ é™¤åï¼Œä¸‹æ¬¡è¿è¡Œæ—¶ç³»ç»Ÿä¼šä»æ–‡ä»¶çŠ¶æ€è‡ªåŠ¨é‡å»º
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        checkpoint_db = os.path.join(self.project_dir, "workflow_checkpoints.db")
        if os.path.exists(checkpoint_db):
            try:
                os.remove(checkpoint_db)
                print(f"  ğŸ—‘ï¸ å·²åˆ é™¤æ£€æŸ¥ç‚¹æ•°æ®åº“: {checkpoint_db}")
                return True
            except Exception as e:
                print(f"  âš ï¸ åˆ é™¤æ£€æŸ¥ç‚¹æ•°æ®åº“å¤±è´¥: {e}")
                return False
        return True
    
    def _update_chapter_memory_file(self, chapter_gte: int) -> int:
        """æ›´æ–°ç« èŠ‚è®°å¿†æ–‡ä»¶ï¼Œç§»é™¤æŒ‡å®šç« èŠ‚åŠä¹‹åçš„æ¡ç›®
        
        Args:
            chapter_gte: ç§»é™¤ç« èŠ‚å· >= æ­¤å€¼çš„æ¡ç›®
            
        Returns:
            ç§»é™¤çš„æ¡ç›®æ•°é‡
        """
        entries = self._load_chapter_memory_entries()
        original_count = len(entries)
        
        filtered_entries = [e for e in entries if e.chapter_number < chapter_gte]
        removed_count = original_count - len(filtered_entries)
        
        if removed_count > 0:
            self._save_chapter_memory_entries(filtered_entries)
            print(f"  ğŸ—‘ï¸ ä»ç« èŠ‚è®°å¿†ä¸­ç§»é™¤ {removed_count} æ¡æ¡ç›®")
        
        return removed_count
    
    def _update_consistency_reports(self, chapter_gte: int) -> int:
        """æ›´æ–°ä¸€è‡´æ€§æŠ¥å‘Šæ–‡ä»¶ï¼Œç§»é™¤æŒ‡å®šç« èŠ‚åŠä¹‹åçš„æ¡ç›®
        
        Args:
            chapter_gte: ç§»é™¤ç« èŠ‚å· >= æ­¤å€¼çš„æ¡ç›®
            
        Returns:
            ç§»é™¤çš„æ¡ç›®æ•°é‡
        """
        if not os.path.exists(self.config.consistency_report_file):
            return 0
        
        try:
            with open(self.config.consistency_report_file, 'r', encoding='utf-8') as f:
                reports = json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return 0
        
        original_count = len(reports)
        filtered_reports = [r for r in reports if r.get("chapter_number", 0) < chapter_gte]
        removed_count = original_count - len(filtered_reports)
        
        if removed_count > 0:
            with open(self.config.consistency_report_file, 'w', encoding='utf-8') as f:
                json.dump(filtered_reports, f, ensure_ascii=False, indent=2)
            print(f"  ğŸ—‘ï¸ ä»ä¸€è‡´æ€§æŠ¥å‘Šä¸­ç§»é™¤ {removed_count} æ¡æ¡ç›®")
        
        return removed_count
    
    def rollback_to_step(self, step_name: str) -> Dict[str, Any]:
        """å›æ»šåˆ°æŒ‡å®šæ­¥éª¤ä¹‹å‰
        
        æ­¥éª¤é¡ºåº: world -> theme_conflict -> characters -> outline -> chapters_plan
        
        Args:
            step_name: è¦å›æ»šåˆ°çš„æ­¥éª¤åç§°
            
        Returns:
            å›æ»šç»“æœï¼š{"deleted_files": [...], "deleted_memories": int}
        """
        import shutil
        
        # æ­¥éª¤é¡ºåºå®šä¹‰
        step_order = ["world", "theme_conflict", "characters", "outline", "chapters_plan"]
        
        if step_name not in step_order:
            raise ValueError(f"æ— æ•ˆçš„æ­¥éª¤åç§°: {step_name}ï¼Œæœ‰æ•ˆå€¼: {step_order}")
        
        step_index = step_order.index(step_name)
        steps_to_delete = step_order[step_index:]
        
        result = {
            "deleted_files": [],
            "deleted_memories": 0
        }
        
        print(f"ğŸ”„ å›æ»šåˆ°æ­¥éª¤ '{step_name}' ä¹‹å‰...")
        
        # åˆ é™¤å„æ­¥éª¤å¯¹åº”çš„æ–‡ä»¶
        step_files = {
            "world": self.config.world_file,
            "theme_conflict": self.config.theme_conflict_file,
            "characters": self.config.characters_file,
            "outline": self.config.outline_file,
        }
        
        for step in steps_to_delete:
            if step in step_files:
                filepath = step_files[step]
                if os.path.exists(filepath):
                    os.remove(filepath)
                    result["deleted_files"].append(filepath)
                    print(f"  ğŸ—‘ï¸ å·²åˆ é™¤: {filepath}")
        
        # å¦‚æœå›æ»šåˆ° outline æˆ–æ›´æ—©ï¼Œéœ€è¦åˆ é™¤æ•´ä¸ª chapters ç›®å½•
        if step_index <= step_order.index("outline"):
            if os.path.exists(self.config.chapters_dir):
                # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
                file_count = len([f for f in os.listdir(self.config.chapters_dir) if os.path.isfile(os.path.join(self.config.chapters_dir, f))])
                shutil.rmtree(self.config.chapters_dir)
                os.makedirs(self.config.chapters_dir, exist_ok=True)
                result["deleted_files"].append(f"chapters/* ({file_count} æ–‡ä»¶)")
                print(f"  ğŸ—‘ï¸ å·²æ¸…ç©º chapters ç›®å½• ({file_count} æ–‡ä»¶)")
            
            # æ¸…ç†ç« èŠ‚è®°å¿†
            self._update_chapter_memory_file(chapter_gte=1)
            
            # æ¸…ç†ä¸€è‡´æ€§æŠ¥å‘Š
            self._update_consistency_reports(chapter_gte=1)
            
            # æ¸…ç† Mem0 è®°å¿†
            if self.mem0_manager:
                try:
                    deleted = self.mem0_manager.delete_memories_by_filter(chapter_index_gte=1)
                    result["deleted_memories"] = deleted
                except Exception as e:
                    print(f"  âš ï¸ æ¸…ç† Mem0 è®°å¿†å¤±è´¥: {e}")
        
        # åˆ é™¤æ£€æŸ¥ç‚¹æ•°æ®åº“
        self._delete_checkpoint_db()
        
        print(f"âœ… å›æ»šå®Œæˆ: åˆ é™¤ {len(result['deleted_files'])} ä¸ªæ–‡ä»¶/ç›®å½•ï¼Œ{result['deleted_memories']} æ¡è®°å¿†")
        return result
    
    def rollback_to_chapter(self, chapter_number: int) -> Dict[str, Any]:
        """å›æ»šåˆ°æŒ‡å®šç« èŠ‚å¼€å§‹ä¹‹å‰
        
        åˆ é™¤æŒ‡å®šç« èŠ‚åŠä¹‹åçš„æ‰€æœ‰ç« èŠ‚å’Œåœºæ™¯æ–‡ä»¶
        
        Args:
            chapter_number: ç« èŠ‚å·ï¼ˆåˆ é™¤æ­¤ç« èŠ‚åŠä¹‹åçš„æ‰€æœ‰å†…å®¹ï¼‰
            
        Returns:
            å›æ»šç»“æœï¼š{"deleted_files": [...], "deleted_memories": int}
        """
        import re
        
        result = {
            "deleted_files": [],
            "deleted_memories": 0
        }
        
        print(f"ğŸ”„ å›æ»šåˆ°ç¬¬ {chapter_number} ç« ä¹‹å‰...")
        
        if not os.path.exists(self.config.chapters_dir):
            print("  âš ï¸ chapters ç›®å½•ä¸å­˜åœ¨")
            return result
        
        # å®šä¹‰æ–‡ä»¶åŒ¹é…æ¨¡å¼
        chapter_pattern = re.compile(r"chapter_(\d{3})(?:_plan)?\.json")
        scene_pattern = re.compile(r"scene_(\d{3})_(\d{3})\.json")
        revision_pattern = re.compile(r"chapter_(\d{3})_revision\.json")
        revised_txt_pattern = re.compile(r"chapter_(\d{3})_revised\.txt")
        
        files_to_delete = []
        
        for filename in os.listdir(self.config.chapters_dir):
            filepath = os.path.join(self.config.chapters_dir, filename)
            
            # æ£€æŸ¥ç« èŠ‚æ–‡ä»¶å’Œè®¡åˆ’æ–‡ä»¶
            chapter_match = chapter_pattern.match(filename)
            if chapter_match:
                ch_num = int(chapter_match.group(1))
                if ch_num >= chapter_number:
                    files_to_delete.append(filepath)
                continue
            
            # æ£€æŸ¥åœºæ™¯æ–‡ä»¶
            scene_match = scene_pattern.match(filename)
            if scene_match:
                ch_num = int(scene_match.group(1))
                if ch_num >= chapter_number:
                    files_to_delete.append(filepath)
                continue
            
            # æ£€æŸ¥ä¿®è®¢æ–‡ä»¶
            revision_match = revision_pattern.match(filename)
            if revision_match:
                ch_num = int(revision_match.group(1))
                if ch_num >= chapter_number:
                    files_to_delete.append(filepath)
                continue
            
            # æ£€æŸ¥ä¿®è®¢æ–‡æœ¬æ–‡ä»¶
            revised_match = revised_txt_pattern.match(filename)
            if revised_match:
                ch_num = int(revised_match.group(1))
                if ch_num >= chapter_number:
                    files_to_delete.append(filepath)
        
        # åˆ é™¤æ–‡ä»¶
        for filepath in files_to_delete:
            try:
                os.remove(filepath)
                result["deleted_files"].append(filepath)
                print(f"  ğŸ—‘ï¸ å·²åˆ é™¤: {os.path.basename(filepath)}")
            except Exception as e:
                print(f"  âš ï¸ åˆ é™¤å¤±è´¥ {filepath}: {e}")
        
        # æ¸…ç†ç« èŠ‚è®°å¿†
        self._update_chapter_memory_file(chapter_gte=chapter_number)
        
        # æ¸…ç†ä¸€è‡´æ€§æŠ¥å‘Š
        self._update_consistency_reports(chapter_gte=chapter_number)
        
        # æ¸…ç† Mem0 è®°å¿†
        if self.mem0_manager:
            try:
                deleted = self.mem0_manager.delete_memories_by_filter(chapter_index_gte=chapter_number)
                result["deleted_memories"] = deleted
            except Exception as e:
                print(f"  âš ï¸ æ¸…ç† Mem0 è®°å¿†å¤±è´¥: {e}")
        
        # åˆ é™¤æ£€æŸ¥ç‚¹æ•°æ®åº“
        self._delete_checkpoint_db()
        
        print(f"âœ… å›æ»šå®Œæˆ: åˆ é™¤ {len(result['deleted_files'])} ä¸ªæ–‡ä»¶ï¼Œ{result['deleted_memories']} æ¡è®°å¿†")
        return result
    
    def rollback_to_scene(self, chapter_number: int, scene_number: int) -> Dict[str, Any]:
        """å›æ»šåˆ°æŒ‡å®šåœºæ™¯å¼€å§‹ä¹‹å‰
        
        åˆ é™¤æŒ‡å®šç« èŠ‚ä¸­æŒ‡å®šåœºæ™¯åŠä¹‹åçš„æ‰€æœ‰åœºæ™¯æ–‡ä»¶ï¼Œ
        åŒæ—¶åˆ é™¤ç« èŠ‚åˆå¹¶æ–‡ä»¶å’Œæ‰€æœ‰åç»­ç« èŠ‚
        
        Args:
            chapter_number: ç« èŠ‚å·
            scene_number: åœºæ™¯å·ï¼ˆåˆ é™¤æ­¤åœºæ™¯åŠä¹‹åçš„æ‰€æœ‰å†…å®¹ï¼‰
            
        Returns:
            å›æ»šç»“æœï¼š{"deleted_files": [...], "deleted_memories": int}
        """
        import re
        
        result = {
            "deleted_files": [],
            "deleted_memories": 0
        }
        
        print(f"ğŸ”„ å›æ»šåˆ°ç¬¬ {chapter_number} ç« ç¬¬ {scene_number} åœºæ™¯ä¹‹å‰...")
        
        if not os.path.exists(self.config.chapters_dir):
            print("  âš ï¸ chapters ç›®å½•ä¸å­˜åœ¨")
            return result
        
        # å®šä¹‰æ–‡ä»¶åŒ¹é…æ¨¡å¼
        chapter_pattern = re.compile(r"chapter_(\d{3})\.json")
        chapter_plan_pattern = re.compile(r"chapter_(\d{3})_plan\.json")
        scene_pattern = re.compile(r"scene_(\d{3})_(\d{3})\.json")
        revision_pattern = re.compile(r"chapter_(\d{3})_revision\.json")
        
        files_to_delete = []
        
        for filename in os.listdir(self.config.chapters_dir):
            filepath = os.path.join(self.config.chapters_dir, filename)
            
            # æ£€æŸ¥ç« èŠ‚æ–‡ä»¶ï¼ˆåˆå¹¶åçš„å®Œæ•´ç« èŠ‚ï¼‰
            chapter_match = chapter_pattern.match(filename)
            if chapter_match:
                ch_num = int(chapter_match.group(1))
                # åˆ é™¤å½“å‰ç« èŠ‚åŠä¹‹åçš„ç« èŠ‚æ–‡ä»¶
                if ch_num >= chapter_number:
                    files_to_delete.append(filepath)
                continue
            
            # æ£€æŸ¥ç« èŠ‚è®¡åˆ’æ–‡ä»¶
            plan_match = chapter_plan_pattern.match(filename)
            if plan_match:
                ch_num = int(plan_match.group(1))
                # åªåˆ é™¤åç»­ç« èŠ‚çš„è®¡åˆ’ï¼Œå½“å‰ç« èŠ‚è®¡åˆ’ä¿ç•™
                if ch_num > chapter_number:
                    files_to_delete.append(filepath)
                continue
            
            # æ£€æŸ¥åœºæ™¯æ–‡ä»¶
            scene_match = scene_pattern.match(filename)
            if scene_match:
                ch_num = int(scene_match.group(1))
                sc_num = int(scene_match.group(2))
                
                # åˆ é™¤åç»­ç« èŠ‚çš„æ‰€æœ‰åœºæ™¯
                if ch_num > chapter_number:
                    files_to_delete.append(filepath)
                # åˆ é™¤å½“å‰ç« èŠ‚ä¸­ >= scene_number çš„åœºæ™¯
                elif ch_num == chapter_number and sc_num >= scene_number:
                    files_to_delete.append(filepath)
                continue
            
            # æ£€æŸ¥ä¿®è®¢æ–‡ä»¶
            revision_match = revision_pattern.match(filename)
            if revision_match:
                ch_num = int(revision_match.group(1))
                if ch_num >= chapter_number:
                    files_to_delete.append(filepath)
        
        # åˆ é™¤æ–‡ä»¶
        for filepath in files_to_delete:
            try:
                os.remove(filepath)
                result["deleted_files"].append(filepath)
                print(f"  ğŸ—‘ï¸ å·²åˆ é™¤: {os.path.basename(filepath)}")
            except Exception as e:
                print(f"  âš ï¸ åˆ é™¤å¤±è´¥ {filepath}: {e}")
        
        # æ¸…ç†ç« èŠ‚è®°å¿†ï¼ˆä»å½“å‰ç« èŠ‚å¼€å§‹æ¸…ç†ï¼‰
        self._update_chapter_memory_file(chapter_gte=chapter_number)
        
        # æ¸…ç†ä¸€è‡´æ€§æŠ¥å‘Š
        self._update_consistency_reports(chapter_gte=chapter_number)
        
        # æ¸…ç† Mem0 è®°å¿†ï¼ˆç²¾ç¡®åˆ°åœºæ™¯ï¼‰
        if self.mem0_manager:
            try:
                deleted = self.mem0_manager.delete_memories_by_filter(
                    chapter_index_gte=chapter_number,
                    scene_index_gte=scene_number,
                    target_chapter_for_scene=chapter_number
                )
                result["deleted_memories"] = deleted
            except Exception as e:
                print(f"  âš ï¸ æ¸…ç† Mem0 è®°å¿†å¤±è´¥: {e}")
        
        # åˆ é™¤æ£€æŸ¥ç‚¹æ•°æ®åº“
        self._delete_checkpoint_db()
        
        print(f"âœ… å›æ»šå®Œæˆ: åˆ é™¤ {len(result['deleted_files'])} ä¸ªæ–‡ä»¶ï¼Œ{result['deleted_memories']} æ¡è®°å¿†")
        return result

    def apply_revision(self, chapter_number: int, rebuild_memory: bool = True):
        """
        åº”ç”¨å¾…ç¡®è®¤çš„ä¿®è®¢ï¼ˆå°†ä¿®è®¢å€™é€‰åº”ç”¨åˆ°ç« èŠ‚ JSONï¼‰

        Args:
            chapter_number: ç« èŠ‚ç¼–å·
            rebuild_memory: æ˜¯å¦é‡å»ºç« èŠ‚è®°å¿†
        """
        revision_status_file = os.path.join(
            self.config.chapters_dir,
            f"chapter_{chapter_number:03d}_revision.json"
        )
        
        if not os.path.exists(revision_status_file):
            raise ValueError(f"ç¬¬{chapter_number}ç« æ²¡æœ‰å¾…ç¡®è®¤çš„ä¿®è®¢")
        
        # è¯»å–ä¿®è®¢çŠ¶æ€
        revision_status = self.load_json(revision_status_file, RevisionStatus)
        if not revision_status:
            raise ValueError(f"æ— æ³•è§£æç¬¬{chapter_number}ç« çš„ä¿®è®¢çŠ¶æ€æ–‡ä»¶")
        
        if revision_status.status != "pending":
            print(f"âš ï¸ ç¬¬{chapter_number}ç« ä¿®è®¢çŠ¶æ€ä¸º {revision_status.status}ï¼Œé pending çŠ¶æ€")
            return
        
        if not revision_status.revised_chapter:
            raise ValueError(f"ç¬¬{chapter_number}ç« ä¿®è®¢çŠ¶æ€ä¸­ç¼ºå°‘ revised_chapter")
        
        print(f"ğŸ“ æ­£åœ¨åº”ç”¨ç¬¬{chapter_number}ç« çš„ä¿®è®¢...")
        
        # å°†ä¿®è®¢å€™é€‰è¦†ç›–åˆ°ç« èŠ‚ JSON
        chapter_file = os.path.join(
            self.config.chapters_dir,
            f"chapter_{chapter_number:03d}.json"
        )
        self.save_json(revision_status.revised_chapter, chapter_file)
        print(f"âœ… ç¬¬{chapter_number}ç« ä¿®è®¢å·²åº”ç”¨åˆ° chapter JSON")
        
        # æ›´æ–°ä¿®è®¢çŠ¶æ€ä¸º accepted
        revision_status.status = "accepted"
        revision_status.decision_at = datetime.now().isoformat()
        self.save_json(revision_status, revision_status_file)
        print(f"âœ… ä¿®è®¢çŠ¶æ€å·²æ›´æ–°ä¸º accepted")
        
        # å¯é€‰ï¼šé‡å»ºç« èŠ‚è®°å¿†
        if rebuild_memory:
            try:
                print(f"ğŸ§  æ­£åœ¨é‡å»ºç¬¬{chapter_number}ç« çš„è®°å¿†æ¡ç›®...")
                # è¯»å–å¤§çº²å’Œè§’è‰²é…ç½®
                outline = self.load_json(self.config.outline_file, Outline)
                if not outline:
                    print(f"âš ï¸ å¤§çº²æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡è®°å¿†é‡å»º")
                    return
                
                chapter_summary_list = [ch for ch in outline.chapters if ch.chapter_number == chapter_number]
                if not chapter_summary_list:
                    print(f"âš ï¸ å¤§çº²ä¸­æœªæ‰¾åˆ°ç¬¬{chapter_number}ç« ï¼Œè·³è¿‡è®°å¿†é‡å»º")
                    return
                chapter_summary = chapter_summary_list[0]
                
                # ç”Ÿæˆåœºæ™¯æ‘˜è¦ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘ï¼‰
                chapter = revision_status.revised_chapter
                scene_summaries = [
                    f"åœºæ™¯{scene.scene_number}: {scene.content[:100]}..."
                    for scene in chapter.scenes
                ]
                aggregated_summary = f"{chapter.chapter_title} - {len(chapter.scenes)}ä¸ªåœºæ™¯"
                
                # ç”Ÿæˆç« èŠ‚è®°å¿†
                from novelgen.runtime.memory import generate_chapter_memory_entry
                memory_entry = generate_chapter_memory_entry(
                    chapter=chapter,
                    outline_summary=chapter_summary,
                    scene_summaries=scene_summaries,
                    aggregated_summary=aggregated_summary,
                    verbose=self.verbose,
                    llm_config=self.config.chapter_memory_chain_config.llm_config
                )
                self._append_chapter_memory_entry(memory_entry)
                print(f"âœ… ç¬¬{chapter_number}ç« è®°å¿†æ¡ç›®å·²é‡å»º")
            except Exception as exc:
                print(f"âš ï¸ é‡å»ºç« èŠ‚è®°å¿†å¤±è´¥ï¼š{exc}")

    def export_chapter(self, chapter_number: int, output_path: Optional[str] = None):
        """
        å¯¼å‡ºå•ä¸ªç« èŠ‚ä¸ºtxtæ–‡ä»¶

        Args:
            chapter_number: ç« èŠ‚ç¼–å·
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤ä¿å­˜åˆ° chapters/chapter_XXX.txt
        """
        # åŠ è½½ç« èŠ‚æ•°æ®
        chapter_file = os.path.join(
            self.config.chapters_dir,
            f"chapter_{chapter_number:03d}.json"
        )
        chapter = self.load_json(chapter_file, GeneratedChapter)
        if not chapter:
            raise ValueError(f"ç« èŠ‚ {chapter_number} ä¸å­˜åœ¨ï¼Œè¯·å…ˆç”Ÿæˆç« èŠ‚")

        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_path is None:
            output_path = os.path.join(
                self.config.chapters_dir,
                f"chapter_{chapter_number:03d}.txt"
            )

        # å¯¼å‡º
        export_chapter_to_txt(chapter, output_path)

    def export_all_chapters(self, output_path: Optional[str] = None):
        """
        å¯¼å‡ºæ‰€æœ‰ç« èŠ‚ä¸ºä¸€ä¸ªtxtæ–‡ä»¶

        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤ä¿å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•çš„ {project_name}_full.txt
        """
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_path is None:
            output_path = os.path.join(
                self.project_dir,
                f"{self.project_name}_full.txt"
            )

        # å¯¼å‡º
        export_all_chapters_to_txt(self.project_dir, output_path)

    def cleanup(self):
        """æ¸…ç†èµ„æºï¼Œå…³é—­æ‰€æœ‰è¿æ¥
        
        åœ¨ç¨‹åºé€€å‡ºå‰è°ƒç”¨ï¼Œç¡®ä¿ï¼š
        1. Mem0/ChromaDB å®¢æˆ·ç«¯æ­£ç¡®å…³é—­
        2. SQLite è¿æ¥å…³é—­
        3. åå°çº¿ç¨‹ç»ˆæ­¢
        
        å¼€å‘è€…: jamesenh, å¼€å‘æ—¶é—´: 2025-11-30
        """
        _debug_log("cleanup() å¼€å§‹")
        
        # 1. å…³é—­ Mem0 ç®¡ç†å™¨
        if self.mem0_manager is not None:
            _debug_log("å…³é—­ Mem0 ç®¡ç†å™¨...")
            start = time.time()
            try:
                self.mem0_manager.close()
                _debug_log(f"Mem0 å…³é—­å®Œæˆï¼Œè€—æ—¶ {time.time() - start:.2f}s")
            except Exception as e:
                _debug_log(f"Mem0 å…³é—­å¤±è´¥: {e}")
        
        # 2. å…³é—­å·¥ä½œæµï¼ˆSQLite è¿æ¥ï¼‰
        if self.workflow is not None:
            _debug_log("å…³é—­å·¥ä½œæµ...")
            start = time.time()
            try:
                # LangGraph çš„ checkpointer å¯èƒ½æŒæœ‰ SQLite è¿æ¥
                # å°è¯•è·å–å¹¶å…³é—­
                if hasattr(self.workflow, 'checkpointer'):
                    checkpointer = self.workflow.checkpointer
                    if hasattr(checkpointer, 'conn'):
                        _debug_log("å…³é—­ SQLite è¿æ¥...")
                        checkpointer.conn.close()
                        _debug_log("SQLite è¿æ¥å·²å…³é—­")
                _debug_log(f"å·¥ä½œæµå…³é—­å®Œæˆï¼Œè€—æ—¶ {time.time() - start:.2f}s")
            except Exception as e:
                _debug_log(f"å·¥ä½œæµå…³é—­å¤±è´¥: {e}")
        
        _debug_log("cleanup() å®Œæˆ")
