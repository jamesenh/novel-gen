"""
LLMå®ä¾‹ç®¡ç†
ç»Ÿä¸€ç®¡ç†LLMå®ä¾‹çš„åˆ›å»º
"""
import time
import json
from typing import Any, Dict, List
from langchain_openai import ChatOpenAI
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.outputs import LLMResult
from langchain_core.messages import BaseMessage
from novelgen.config import LLMConfig


class VerboseCallbackHandler(BaseCallbackHandler):
    """è¯¦ç»†æ—¥å¿—å›è°ƒå¤„ç†å™¨"""
    
    def __init__(self):
        self.start_time = None
        self.end_time = None
        self.prompts = []
        self.total_tokens = 0
        self.prompt_tokens = 0
        self.completion_tokens = 0
    
    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:
        """LLMå¼€å§‹è°ƒç”¨æ—¶"""
        self.start_time = time.time()
        self.prompts = prompts
        
        print("\n" + "="*80)
        print("ğŸ¤– LLMè°ƒç”¨å¼€å§‹")
        print("="*80)
        print("\nğŸ“ å®Œæ•´æç¤ºè¯ï¼š")
        print("-"*80)
        for i, prompt in enumerate(prompts, 1):
            print(f"\n[æç¤ºè¯ {i}]")
            print(prompt)
            print("-"*80)
    
    def on_chat_model_start(self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs) -> None:
        """èŠå¤©æ¨¡å‹å¼€å§‹è°ƒç”¨æ—¶"""
        self.start_time = time.time()
        
        print("\n" + "="*80)
        print("ğŸ¤– LLMè°ƒç”¨å¼€å§‹")
        print("="*80)
        print("\nğŸ“ å®Œæ•´æç¤ºè¯ï¼š")
        print("-"*80)
        
        for i, message_list in enumerate(messages, 1):
            print(f"\n[å¯¹è¯ {i}]")
            for msg in message_list:
                role = msg.__class__.__name__.replace("Message", "")
                content = msg.content
                print(f"\n[{role}]")
                print(content)
            print("-"*80)
    
    def on_llm_end(self, response: LLMResult, **kwargs) -> None:
        """LLMè°ƒç”¨ç»“æŸæ—¶"""
        self.end_time = time.time()
        elapsed_time = self.end_time - self.start_time
        
        # æå–tokenä½¿ç”¨æƒ…å†µ
        if response.llm_output and 'token_usage' in response.llm_output:
            token_usage = response.llm_output['token_usage']
            self.total_tokens = token_usage.get('total_tokens', 0)
            self.prompt_tokens = token_usage.get('prompt_tokens', 0)
            self.completion_tokens = token_usage.get('completion_tokens', 0)
        
        print("\n" + "="*80)
        print("âœ… LLMè°ƒç”¨å®Œæˆ")
        print("="*80)
        print(f"\nâ±ï¸  å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")
        print(f"\nğŸ¯ Tokenä½¿ç”¨æƒ…å†µ:")
        print(f"  â€¢ æç¤ºè¯Token: {self.prompt_tokens}")
        print(f"  â€¢ ç”ŸæˆToken: {self.completion_tokens}")
        print(f"  â€¢ æ€»è®¡Token: {self.total_tokens}")
        print("\n" + "="*80 + "\n")
    
    def on_llm_error(self, error: Exception, **kwargs) -> None:
        """LLMè°ƒç”¨å‡ºé”™æ—¶"""
        self.end_time = time.time()
        elapsed_time = self.end_time - self.start_time if self.start_time else 0
        
        print("\n" + "="*80)
        print("âŒ LLMè°ƒç”¨å‡ºé”™")
        print("="*80)
        print(f"\nâ±ï¸  å·²è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"\nâ— é”™è¯¯ä¿¡æ¯: {error}")
        print("\n" + "="*80 + "\n")


def get_llm(config: LLMConfig = None, verbose: bool = False):
    """
    è·å–LLMå®ä¾‹
    
    Args:
        config: LLMé…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        verbose: æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º
        
    Returns:
        ChatOpenAIå®ä¾‹
    """
    if config is None:
        config = LLMConfig()
    
    callbacks = []
    if verbose:
        callbacks.append(VerboseCallbackHandler())
    
    extra_body = None
    if config.base_url and "api-inference.modelscope.cn" in config.base_url and "Qwen3-32B" in config.model_name:
        extra_body = {"enable_thinking": False}
    
    return ChatOpenAI(
        model=config.model_name,
        temperature=config.temperature,
        max_tokens=config.max_tokens,
        api_key=config.api_key,
        base_url=config.base_url,
        callbacks=callbacks if callbacks else None,
        extra_body=extra_body
    )

